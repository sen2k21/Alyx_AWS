
------------------------------------------ New Lab --------------------------------------------------------

0. IAM changes  - GlueRole -> edit that role and allow S3fullaccess and RDSFullaccess
1. Create s3 bucket - input-for-glue
   	upload contents of glue.zip
2. Create RDS (free tier, public database)
	Mysql, execute -> deptemp.txt in innodb
3. Crawler s3 bucket
	  -> Create 
		1. name - mys3crawler
		2. Choose data store - s3
			Connection - empty
		3.	Crawl data in
			Specified path in my account
			Include path - s3://input-for-glue
			Add another data store - No
		4.	Create an IAM role - select role1
		5.	Frequency - run on demand
		6.	Database
				add database
				Database name  - mys3db
		next
		Create 
	  -> select crawler -> run crawler
		number of tables affected
	confirm databases(Glue)
		your db -> check tables for information

4. Crawler RDS 
	-> Add Connection
		->Connection Name -> mysqlrds
	  	  connection type- RDS
		  Database engine - mysql
		  No SSL
		  	Next
		 Instance -> select
		 Database name - innodb
		 username - admin
		 password -
	Test the connection -
		  	
	-> add crawler -> 
		1. name - myRDScrawler
			datastores, crawl all the folders
		2. Choose data store - 
			Choose a data store - jdbc
			Connection -> (Add connection ->
					Name - jdbc:mysql://db1.chidkemxak9r.us-east-1.rds.amazonaws.com:3306/db1
					Connection type - RDS	
					Include path - innodb) or create connection earlier
	---------------------------> new windows for VPC-> 
				EndPoint ->Create EndPoint ->  select RDS -> Create endpoint
							       select s3 -> Create endpoint
	-------------------------->ec2 -> network security -> add new inboud rule->
							All TCP ->port range - 0-65535 -> source -> (same sg group - default)
		4.	Create an IAM role - select role1
		5.	Frequency - run on demand
		select crawler -> run crawler
		number of tables affected
	confirm databases(Glue)
		your db -> check tables for information

5. Confirmation
AWS Glue-> Databases -> Connections -. 
	select sql connection -> select IAM Role -> test connection -> successful


------------------------------------------ Old Lab --------------------------------------------------------

Lab  2- Classfier
	Create a classifier 
		Classifier name - empxml
		Classifier type - xml
		row tag - employee 

	Upload two files in s3 bucket
	File1 - <?xml version="1.0" ?>
		<employees>
			<employee>
				<empno>10</empno>
				<empname>aaa</empname>
				<salary>1000</salary>
			</employee>
			<employee>
				<empno>20</empno>
				<empname>bbbb</empname>
				<salary>2000</salary>
			</employee>
			<employee>
				<empno>30</empno>
				<empname>CCC</empname>
				<salary>3000</salary>
			</employee>

		</employees>
	Run crawler -> check tables

	

-------------------------------
Lab 1 - Crawler

1. Create s3 bucket - csv-samples-for-dms
    5 /6 files -> csv (with header, without header), json , xml (https://github.com/Vaishali-Tapaswi/Alyx_AWS/tree/main/samplefiles)
2. Crawler
  -> Create 
			1. name - crawler1
			2. Choose data store - s3
				Connection - empty
			3.	Crawl data in
					Specified path in my account
				Include path - s3://csv-samples-for-dms
				Add another data store - No
			4.	Create an IAM role - role1
			5.	Frequency - run on demand
			6.	Database
					add database
							Database name  - mysqldb
							Resource link name - arn of your db
							next
			Create 
	select crawler -> run crawler
		number of tables affected
3. database
		your db -> check tables for information
